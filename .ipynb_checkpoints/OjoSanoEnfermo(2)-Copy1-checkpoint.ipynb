{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import keras as ks\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import imagenet_utils\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn.utils import shuffle\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPool2D, GlobalAveragePooling2D, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "weights = ks.applications.mobilenet_v2.MobileNetV2(input_shape=(224,224,3), include_top=False, weights='imagenet', pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(f, l, m):\n",
    "    e_l = []\n",
    "    feat_l = []\n",
    "    for filename in tqdm(os.listdir(f)):\n",
    "        img_path = os.path.join(f, filename)\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        e = m.predict(x)\n",
    "\n",
    "        e_l.append(e)\n",
    "        feat_l.append(l)\n",
    "        \n",
    "    return e_l, feat_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(f, m):\n",
    "    img_path = os.path.join('', f)\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    e = m.predict(x)\n",
    "        \n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:59<00:00, 13.09it/s]\n"
     ]
    }
   ],
   "source": [
    "enfermos, feat_enfermos = load_images_from_folder('fondo_de_ojo_train/enfermo/', 0, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [01:02<00:00, 13.10it/s]\n"
     ]
    }
   ],
   "source": [
    "sanos, feat_sanos = load_images_from_folder('fondo_de_ojo_train/sano/', 1, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sanos + enfermos\n",
    "Y = feat_sanos + feat_enfermos\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X,Y = shuffle(X, Y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (1313, 1, 1280) (1313,)\n",
      "Testing data shape :  (329, 1, 1280) (329,)\n"
     ]
    }
   ],
   "source": [
    "train_X,test_X,train_Y,test_Y = train_test_split(X,Y,test_size=0.2)\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.unique(train_Y)\n",
    "nClasses = len(classes)\n",
    "nClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: 1\n",
      "After conversion to one-hot: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    " \n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label:', train_Y[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, valid_X, train_Y, valid_Y = train_test_split(train_X, train_Y_one_hot, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1, 1280)           1639680   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1280)              1639680   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 3,281,922\n",
      "Trainable params: 3,281,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INIT_LR = 1e-3\n",
    "epochs = 150\n",
    "batch_size = 64\n",
    "exp_name = 'e02'\n",
    "\n",
    "mobile = Sequential()\n",
    "mobile.add(Dense(input_shape=[1,train_X[0][0].shape[0]], units=train_X[0][0].shape[0]))\n",
    "mobile.add(Flatten())\n",
    "mobile.add(Dropout(0.5))\n",
    "mobile.add(Dense(input_shape=[1,train_X[0][0].shape[0]], units=train_X[0][0].shape[0], activation='linear'))\n",
    "mobile.add(Dropout(0.5)) \n",
    "mobile.add(Dense(2, input_shape=(train_X[:][:].shape[0],), activation='softmax'))\n",
    "\n",
    "mobile.summary()\n",
    "\n",
    "mobile.compile(loss=ks.losses.categorical_crossentropy, optimizer=ks.optimizers.Adagrad(lr=INIT_LR, decay=INIT_LR / 100),metrics=['accuracy'])\n",
    "\n",
    "experiment_path = os.path.join(' ./experimento/' + exp_name)\n",
    "if not os.path.exists(experiment_path):\n",
    "    os.makedirs(experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1050 samples, validate on 263 samples\n",
      "Epoch 1/150\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.6896 - acc: 0.5457 - val_loss: 0.6825 - val_acc: 0.6540\n",
      "Epoch 2/150\n",
      "1050/1050 [==============================] - 1s 600us/step - loss: 0.6764 - acc: 0.5924 - val_loss: 0.6710 - val_acc: 0.5856\n",
      "Epoch 3/150\n",
      "1050/1050 [==============================] - 1s 638us/step - loss: 0.6611 - acc: 0.6495 - val_loss: 0.6765 - val_acc: 0.5703\n",
      "Epoch 4/150\n",
      "1050/1050 [==============================] - 1s 745us/step - loss: 0.6462 - acc: 0.6571 - val_loss: 0.6539 - val_acc: 0.6350\n",
      "Epoch 5/150\n",
      "1050/1050 [==============================] - 1s 589us/step - loss: 0.6326 - acc: 0.6676 - val_loss: 0.6466 - val_acc: 0.6388\n",
      "Epoch 6/150\n",
      "1050/1050 [==============================] - 1s 731us/step - loss: 0.6233 - acc: 0.6610 - val_loss: 0.6522 - val_acc: 0.6426\n",
      "Epoch 7/150\n",
      "1050/1050 [==============================] - 1s 680us/step - loss: 0.6152 - acc: 0.6581 - val_loss: 0.6385 - val_acc: 0.6388\n",
      "Epoch 8/150\n",
      "1050/1050 [==============================] - 1s 584us/step - loss: 0.6103 - acc: 0.6543 - val_loss: 0.6332 - val_acc: 0.6616\n",
      "Epoch 9/150\n",
      "1050/1050 [==============================] - 1s 586us/step - loss: 0.6004 - acc: 0.6676 - val_loss: 0.6371 - val_acc: 0.6502\n",
      "Epoch 10/150\n",
      "1050/1050 [==============================] - 1s 578us/step - loss: 0.5978 - acc: 0.6752 - val_loss: 0.6288 - val_acc: 0.6540\n",
      "Epoch 11/150\n",
      "1050/1050 [==============================] - 1s 581us/step - loss: 0.5900 - acc: 0.6743 - val_loss: 0.6465 - val_acc: 0.5894\n",
      "Epoch 12/150\n",
      "1050/1050 [==============================] - 1s 703us/step - loss: 0.5877 - acc: 0.6838 - val_loss: 0.6278 - val_acc: 0.6350\n",
      "Epoch 13/150\n",
      "1050/1050 [==============================] - 1s 669us/step - loss: 0.5845 - acc: 0.6924 - val_loss: 0.6248 - val_acc: 0.6616\n",
      "Epoch 14/150\n",
      "1050/1050 [==============================] - 1s 646us/step - loss: 0.5803 - acc: 0.6952 - val_loss: 0.6249 - val_acc: 0.6692\n",
      "Epoch 15/150\n",
      "1050/1050 [==============================] - 1s 582us/step - loss: 0.5751 - acc: 0.6933 - val_loss: 0.6328 - val_acc: 0.6198\n",
      "Epoch 16/150\n",
      "1050/1050 [==============================] - 1s 619us/step - loss: 0.5711 - acc: 0.7019 - val_loss: 0.6224 - val_acc: 0.6616\n",
      "Epoch 17/150\n",
      "1050/1050 [==============================] - 1s 614us/step - loss: 0.5662 - acc: 0.7124 - val_loss: 0.6281 - val_acc: 0.6844\n",
      "Epoch 18/150\n",
      "1050/1050 [==============================] - 1s 634us/step - loss: 0.5671 - acc: 0.7048 - val_loss: 0.6203 - val_acc: 0.6540\n",
      "Epoch 19/150\n",
      "1050/1050 [==============================] - 1s 672us/step - loss: 0.5622 - acc: 0.7114 - val_loss: 0.6196 - val_acc: 0.6578\n",
      "Epoch 20/150\n",
      "1050/1050 [==============================] - 1s 604us/step - loss: 0.5600 - acc: 0.7076 - val_loss: 0.6198 - val_acc: 0.6502\n",
      "Epoch 21/150\n",
      "1050/1050 [==============================] - 1s 595us/step - loss: 0.5558 - acc: 0.7048 - val_loss: 0.6206 - val_acc: 0.6616\n",
      "Epoch 22/150\n",
      "1050/1050 [==============================] - 1s 598us/step - loss: 0.5566 - acc: 0.7162 - val_loss: 0.6186 - val_acc: 0.6502\n",
      "Epoch 23/150\n",
      "1050/1050 [==============================] - 1s 573us/step - loss: 0.5543 - acc: 0.7152 - val_loss: 0.6216 - val_acc: 0.6654\n",
      "Epoch 24/150\n",
      "1050/1050 [==============================] - 1s 576us/step - loss: 0.5507 - acc: 0.7114 - val_loss: 0.6190 - val_acc: 0.6616\n",
      "Epoch 25/150\n",
      "1050/1050 [==============================] - 1s 573us/step - loss: 0.5480 - acc: 0.7133 - val_loss: 0.6182 - val_acc: 0.6654\n",
      "Epoch 26/150\n",
      "1050/1050 [==============================] - 1s 575us/step - loss: 0.5463 - acc: 0.7171 - val_loss: 0.6154 - val_acc: 0.6654\n",
      "Epoch 27/150\n",
      "1050/1050 [==============================] - 1s 700us/step - loss: 0.5450 - acc: 0.7143 - val_loss: 0.6156 - val_acc: 0.6616\n",
      "Epoch 28/150\n",
      "1050/1050 [==============================] - 1s 674us/step - loss: 0.5373 - acc: 0.7257 - val_loss: 0.6153 - val_acc: 0.6654\n",
      "Epoch 29/150\n",
      "1050/1050 [==============================] - 1s 760us/step - loss: 0.5390 - acc: 0.7229 - val_loss: 0.6174 - val_acc: 0.6502\n",
      "Epoch 30/150\n",
      "1050/1050 [==============================] - 1s 650us/step - loss: 0.5377 - acc: 0.7229 - val_loss: 0.6153 - val_acc: 0.6616\n",
      "Epoch 31/150\n",
      "1050/1050 [==============================] - 1s 714us/step - loss: 0.5373 - acc: 0.7248 - val_loss: 0.6142 - val_acc: 0.6654\n",
      "Epoch 32/150\n",
      "1050/1050 [==============================] - 1s 588us/step - loss: 0.5348 - acc: 0.7143 - val_loss: 0.6140 - val_acc: 0.6654\n",
      "Epoch 33/150\n",
      "1050/1050 [==============================] - 1s 580us/step - loss: 0.5327 - acc: 0.7219 - val_loss: 0.6223 - val_acc: 0.6540\n",
      "Epoch 34/150\n",
      "1050/1050 [==============================] - 1s 593us/step - loss: 0.5315 - acc: 0.7314 - val_loss: 0.6143 - val_acc: 0.6654\n",
      "Epoch 35/150\n",
      "1050/1050 [==============================] - 1s 590us/step - loss: 0.5313 - acc: 0.7238 - val_loss: 0.6138 - val_acc: 0.6654\n",
      "Epoch 36/150\n",
      "1050/1050 [==============================] - 1s 596us/step - loss: 0.5291 - acc: 0.7229 - val_loss: 0.6113 - val_acc: 0.6654\n",
      "Epoch 37/150\n",
      "1050/1050 [==============================] - 1s 691us/step - loss: 0.5286 - acc: 0.7295 - val_loss: 0.6280 - val_acc: 0.6540\n",
      "Epoch 38/150\n",
      "1050/1050 [==============================] - 1s 594us/step - loss: 0.5282 - acc: 0.7314 - val_loss: 0.6108 - val_acc: 0.6730\n",
      "Epoch 39/150\n",
      "1050/1050 [==============================] - 1s 763us/step - loss: 0.5281 - acc: 0.7238 - val_loss: 0.6132 - val_acc: 0.6578\n",
      "Epoch 40/150\n",
      "1050/1050 [==============================] - 1s 622us/step - loss: 0.5210 - acc: 0.7381 - val_loss: 0.6096 - val_acc: 0.6768\n",
      "Epoch 41/150\n",
      "1050/1050 [==============================] - 1s 596us/step - loss: 0.5257 - acc: 0.7267 - val_loss: 0.6119 - val_acc: 0.6616\n",
      "Epoch 42/150\n",
      "1050/1050 [==============================] - 1s 592us/step - loss: 0.5147 - acc: 0.7429 - val_loss: 0.6097 - val_acc: 0.6768\n",
      "Epoch 43/150\n",
      "1050/1050 [==============================] - 1s 588us/step - loss: 0.5199 - acc: 0.7381 - val_loss: 0.6139 - val_acc: 0.6540\n",
      "Epoch 44/150\n",
      "1050/1050 [==============================] - 1s 594us/step - loss: 0.5141 - acc: 0.7410 - val_loss: 0.6145 - val_acc: 0.6540\n",
      "Epoch 45/150\n",
      "1050/1050 [==============================] - 1s 590us/step - loss: 0.5120 - acc: 0.7419 - val_loss: 0.6091 - val_acc: 0.6578\n",
      "Epoch 46/150\n",
      "1050/1050 [==============================] - 1s 594us/step - loss: 0.5144 - acc: 0.7390 - val_loss: 0.6085 - val_acc: 0.6616\n",
      "Epoch 47/150\n",
      "1050/1050 [==============================] - 1s 590us/step - loss: 0.5135 - acc: 0.7419 - val_loss: 0.6106 - val_acc: 0.6654\n",
      "Epoch 48/150\n",
      "1050/1050 [==============================] - 1s 598us/step - loss: 0.5085 - acc: 0.7467 - val_loss: 0.6124 - val_acc: 0.6578\n",
      "Epoch 49/150\n",
      "1050/1050 [==============================] - 1s 598us/step - loss: 0.5113 - acc: 0.7390 - val_loss: 0.6096 - val_acc: 0.6730\n",
      "Epoch 50/150\n",
      "1050/1050 [==============================] - 1s 602us/step - loss: 0.5109 - acc: 0.7324 - val_loss: 0.6077 - val_acc: 0.6692\n",
      "Epoch 51/150\n",
      "1050/1050 [==============================] - 1s 586us/step - loss: 0.5082 - acc: 0.7448 - val_loss: 0.6094 - val_acc: 0.6616\n",
      "Epoch 52/150\n",
      "1050/1050 [==============================] - 1s 594us/step - loss: 0.5093 - acc: 0.7438 - val_loss: 0.6086 - val_acc: 0.6730\n",
      "Epoch 53/150\n",
      "1050/1050 [==============================] - 1s 591us/step - loss: 0.5034 - acc: 0.7371 - val_loss: 0.6061 - val_acc: 0.6730\n",
      "Epoch 54/150\n",
      "1050/1050 [==============================] - 1s 587us/step - loss: 0.5010 - acc: 0.7448 - val_loss: 0.6327 - val_acc: 0.6540\n",
      "Epoch 55/150\n",
      "1050/1050 [==============================] - 1s 631us/step - loss: 0.4976 - acc: 0.7514 - val_loss: 0.6193 - val_acc: 0.6388\n",
      "Epoch 56/150\n",
      "1050/1050 [==============================] - 1s 721us/step - loss: 0.4980 - acc: 0.7524 - val_loss: 0.6112 - val_acc: 0.6540\n",
      "Epoch 57/150\n",
      "1050/1050 [==============================] - 1s 623us/step - loss: 0.5020 - acc: 0.7429 - val_loss: 0.6071 - val_acc: 0.6692\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 1s 642us/step - loss: 0.4974 - acc: 0.7419 - val_loss: 0.6048 - val_acc: 0.6730\n",
      "Epoch 59/150\n",
      "1050/1050 [==============================] - 1s 612us/step - loss: 0.4975 - acc: 0.7467 - val_loss: 0.6073 - val_acc: 0.6768\n",
      "Epoch 60/150\n",
      "1050/1050 [==============================] - 1s 615us/step - loss: 0.4966 - acc: 0.7457 - val_loss: 0.6047 - val_acc: 0.6806\n",
      "Epoch 61/150\n",
      "1050/1050 [==============================] - 1s 583us/step - loss: 0.4940 - acc: 0.7419 - val_loss: 0.6065 - val_acc: 0.6730\n",
      "Epoch 62/150\n",
      "1050/1050 [==============================] - 1s 604us/step - loss: 0.4933 - acc: 0.7429 - val_loss: 0.6041 - val_acc: 0.6730\n",
      "Epoch 63/150\n",
      "1050/1050 [==============================] - 1s 618us/step - loss: 0.4923 - acc: 0.7514 - val_loss: 0.6126 - val_acc: 0.6502\n",
      "Epoch 64/150\n",
      "1050/1050 [==============================] - 1s 590us/step - loss: 0.4857 - acc: 0.7581 - val_loss: 0.6039 - val_acc: 0.6806\n",
      "Epoch 65/150\n",
      "1050/1050 [==============================] - 1s 587us/step - loss: 0.4963 - acc: 0.7467 - val_loss: 0.6053 - val_acc: 0.6730\n",
      "Epoch 66/150\n",
      "1050/1050 [==============================] - 1s 639us/step - loss: 0.4880 - acc: 0.7486 - val_loss: 0.6051 - val_acc: 0.6730\n",
      "Epoch 67/150\n",
      "1050/1050 [==============================] - 1s 862us/step - loss: 0.4845 - acc: 0.7629 - val_loss: 0.6085 - val_acc: 0.6616\n",
      "Epoch 68/150\n",
      "1050/1050 [==============================] - 1s 713us/step - loss: 0.4876 - acc: 0.7552 - val_loss: 0.6045 - val_acc: 0.6654\n",
      "Epoch 69/150\n",
      "1050/1050 [==============================] - 1s 653us/step - loss: 0.4806 - acc: 0.7667 - val_loss: 0.6030 - val_acc: 0.6844\n",
      "Epoch 70/150\n",
      "1050/1050 [==============================] - 1s 602us/step - loss: 0.4784 - acc: 0.7524 - val_loss: 0.6030 - val_acc: 0.6806\n",
      "Epoch 71/150\n",
      "1050/1050 [==============================] - 1s 590us/step - loss: 0.4816 - acc: 0.7590 - val_loss: 0.6103 - val_acc: 0.6578\n",
      "Epoch 72/150\n",
      "1050/1050 [==============================] - 1s 604us/step - loss: 0.4787 - acc: 0.7543 - val_loss: 0.6030 - val_acc: 0.6844\n",
      "Epoch 73/150\n",
      "1050/1050 [==============================] - 1s 596us/step - loss: 0.4815 - acc: 0.7581 - val_loss: 0.6037 - val_acc: 0.6844\n",
      "Epoch 74/150\n",
      "1050/1050 [==============================] - 1s 601us/step - loss: 0.4798 - acc: 0.7752 - val_loss: 0.6028 - val_acc: 0.6806\n",
      "Epoch 75/150\n",
      "1050/1050 [==============================] - 1s 609us/step - loss: 0.4753 - acc: 0.7695 - val_loss: 0.6026 - val_acc: 0.6806\n",
      "Epoch 76/150\n",
      "1050/1050 [==============================] - 1s 679us/step - loss: 0.4737 - acc: 0.7543 - val_loss: 0.6090 - val_acc: 0.6654\n",
      "Epoch 77/150\n",
      "1050/1050 [==============================] - 1s 680us/step - loss: 0.4691 - acc: 0.7724 - val_loss: 0.6034 - val_acc: 0.6806\n",
      "Epoch 78/150\n",
      "1050/1050 [==============================] - 1s 616us/step - loss: 0.4712 - acc: 0.7648 - val_loss: 0.6248 - val_acc: 0.6692\n",
      "Epoch 79/150\n",
      "1050/1050 [==============================] - 1s 684us/step - loss: 0.4730 - acc: 0.7648 - val_loss: 0.6065 - val_acc: 0.6654\n",
      "Epoch 80/150\n",
      "1050/1050 [==============================] - 1s 628us/step - loss: 0.4747 - acc: 0.7562 - val_loss: 0.6070 - val_acc: 0.6654\n",
      "Epoch 81/150\n",
      "1050/1050 [==============================] - 1s 682us/step - loss: 0.4666 - acc: 0.7752 - val_loss: 0.6077 - val_acc: 0.6654\n",
      "Epoch 82/150\n",
      "1050/1050 [==============================] - 1s 613us/step - loss: 0.4667 - acc: 0.7657 - val_loss: 0.6057 - val_acc: 0.6806\n",
      "Epoch 83/150\n",
      "1050/1050 [==============================] - 1s 600us/step - loss: 0.4698 - acc: 0.7667 - val_loss: 0.6077 - val_acc: 0.6692\n",
      "Epoch 84/150\n",
      "1050/1050 [==============================] - 1s 593us/step - loss: 0.4707 - acc: 0.7676 - val_loss: 0.6105 - val_acc: 0.6578\n",
      "Epoch 85/150\n",
      "1050/1050 [==============================] - 1s 596us/step - loss: 0.4676 - acc: 0.7724 - val_loss: 0.6102 - val_acc: 0.6578\n",
      "Epoch 86/150\n",
      "1050/1050 [==============================] - 1s 605us/step - loss: 0.4632 - acc: 0.7714 - val_loss: 0.6045 - val_acc: 0.6654\n",
      "Epoch 87/150\n",
      "1050/1050 [==============================] - 1s 603us/step - loss: 0.4609 - acc: 0.7762 - val_loss: 0.6089 - val_acc: 0.6692\n",
      "Epoch 88/150\n",
      "1050/1050 [==============================] - 1s 607us/step - loss: 0.4602 - acc: 0.7857 - val_loss: 0.6040 - val_acc: 0.6730\n",
      "Epoch 89/150\n",
      "1050/1050 [==============================] - 1s 609us/step - loss: 0.4612 - acc: 0.7705 - val_loss: 0.6066 - val_acc: 0.6768\n",
      "Epoch 90/150\n",
      "1050/1050 [==============================] - 1s 602us/step - loss: 0.4615 - acc: 0.7743 - val_loss: 0.6027 - val_acc: 0.6692\n",
      "Epoch 91/150\n",
      "1050/1050 [==============================] - 1s 605us/step - loss: 0.4572 - acc: 0.7781 - val_loss: 0.6051 - val_acc: 0.6768\n",
      "Epoch 92/150\n",
      "1050/1050 [==============================] - 1s 604us/step - loss: 0.4638 - acc: 0.7771 - val_loss: 0.6081 - val_acc: 0.6768\n",
      "Epoch 93/150\n",
      "1050/1050 [==============================] - 1s 598us/step - loss: 0.4563 - acc: 0.7752 - val_loss: 0.6052 - val_acc: 0.6768\n",
      "Epoch 94/150\n",
      "1050/1050 [==============================] - 1s 619us/step - loss: 0.4511 - acc: 0.7790 - val_loss: 0.6041 - val_acc: 0.6768\n",
      "Epoch 95/150\n",
      "1050/1050 [==============================] - 1s 613us/step - loss: 0.4524 - acc: 0.7667 - val_loss: 0.6029 - val_acc: 0.6692\n",
      "Epoch 96/150\n",
      "1050/1050 [==============================] - 1s 605us/step - loss: 0.4525 - acc: 0.7733 - val_loss: 0.6054 - val_acc: 0.6768\n",
      "Epoch 97/150\n",
      "1050/1050 [==============================] - 1s 603us/step - loss: 0.4543 - acc: 0.7771 - val_loss: 0.6042 - val_acc: 0.6730\n",
      "Epoch 98/150\n",
      "1050/1050 [==============================] - 1s 602us/step - loss: 0.4513 - acc: 0.7800 - val_loss: 0.6080 - val_acc: 0.6654\n",
      "Epoch 99/150\n",
      "1050/1050 [==============================] - 1s 608us/step - loss: 0.4482 - acc: 0.7819 - val_loss: 0.6040 - val_acc: 0.6692\n",
      "Epoch 100/150\n",
      "1050/1050 [==============================] - 1s 602us/step - loss: 0.4485 - acc: 0.7876 - val_loss: 0.6039 - val_acc: 0.6692\n",
      "Epoch 101/150\n",
      "1050/1050 [==============================] - 1s 604us/step - loss: 0.4477 - acc: 0.7867 - val_loss: 0.6072 - val_acc: 0.6692\n",
      "Epoch 102/150\n",
      "1050/1050 [==============================] - 1s 598us/step - loss: 0.4447 - acc: 0.7857 - val_loss: 0.6036 - val_acc: 0.6692\n",
      "Epoch 103/150\n",
      "1050/1050 [==============================] - 1s 600us/step - loss: 0.4432 - acc: 0.7819 - val_loss: 0.6106 - val_acc: 0.6844\n",
      "Epoch 104/150\n",
      "1050/1050 [==============================] - 1s 616us/step - loss: 0.4429 - acc: 0.7857 - val_loss: 0.6052 - val_acc: 0.6730\n",
      "Epoch 105/150\n",
      "1050/1050 [==============================] - 1s 613us/step - loss: 0.4394 - acc: 0.7876 - val_loss: 0.6066 - val_acc: 0.6654\n",
      "Epoch 106/150\n",
      "1050/1050 [==============================] - 1s 607us/step - loss: 0.4368 - acc: 0.7914 - val_loss: 0.6048 - val_acc: 0.6654\n",
      "Epoch 107/150\n",
      "1050/1050 [==============================] - 1s 604us/step - loss: 0.4387 - acc: 0.7924 - val_loss: 0.6100 - val_acc: 0.6768\n",
      "Epoch 108/150\n",
      "1050/1050 [==============================] - 1s 660us/step - loss: 0.4445 - acc: 0.7857 - val_loss: 0.6068 - val_acc: 0.6692\n",
      "Epoch 109/150\n",
      "1050/1050 [==============================] - 1s 608us/step - loss: 0.4317 - acc: 0.7990 - val_loss: 0.6046 - val_acc: 0.6654\n",
      "Epoch 110/150\n",
      "1050/1050 [==============================] - 1s 600us/step - loss: 0.4377 - acc: 0.7914 - val_loss: 0.6064 - val_acc: 0.6730\n",
      "Epoch 111/150\n",
      "1050/1050 [==============================] - 1s 605us/step - loss: 0.4362 - acc: 0.7981 - val_loss: 0.6054 - val_acc: 0.6768\n",
      "Epoch 112/150\n",
      "1050/1050 [==============================] - 1s 603us/step - loss: 0.4336 - acc: 0.7924 - val_loss: 0.6067 - val_acc: 0.6730\n",
      "Epoch 113/150\n",
      "1050/1050 [==============================] - 1s 611us/step - loss: 0.4362 - acc: 0.7905 - val_loss: 0.6090 - val_acc: 0.6806\n",
      "Epoch 114/150\n",
      "1050/1050 [==============================] - 1s 611us/step - loss: 0.4314 - acc: 0.7981 - val_loss: 0.6063 - val_acc: 0.6692\n",
      "Epoch 115/150\n",
      "1050/1050 [==============================] - 1s 617us/step - loss: 0.4352 - acc: 0.7933 - val_loss: 0.6066 - val_acc: 0.6730\n",
      "Epoch 116/150\n",
      "1050/1050 [==============================] - 1s 619us/step - loss: 0.4326 - acc: 0.7952 - val_loss: 0.6062 - val_acc: 0.6692\n",
      "Epoch 117/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 1s 713us/step - loss: 0.4310 - acc: 0.7990 - val_loss: 0.6126 - val_acc: 0.6768\n",
      "Epoch 118/150\n",
      "1050/1050 [==============================] - 1s 746us/step - loss: 0.4309 - acc: 0.7905 - val_loss: 0.6147 - val_acc: 0.6768\n",
      "Epoch 119/150\n",
      "1050/1050 [==============================] - 1s 723us/step - loss: 0.4272 - acc: 0.8038 - val_loss: 0.6134 - val_acc: 0.6768\n",
      "Epoch 120/150\n",
      "1050/1050 [==============================] - 1s 694us/step - loss: 0.4228 - acc: 0.7990 - val_loss: 0.6101 - val_acc: 0.6768\n",
      "Epoch 121/150\n",
      "1050/1050 [==============================] - 1s 683us/step - loss: 0.4268 - acc: 0.8019 - val_loss: 0.6103 - val_acc: 0.6768\n",
      "Epoch 122/150\n",
      "1050/1050 [==============================] - 1s 621us/step - loss: 0.4266 - acc: 0.7905 - val_loss: 0.6088 - val_acc: 0.6654\n",
      "Epoch 123/150\n",
      "1050/1050 [==============================] - 1s 648us/step - loss: 0.4258 - acc: 0.7990 - val_loss: 0.6097 - val_acc: 0.6616\n",
      "Epoch 124/150\n",
      "1050/1050 [==============================] - 1s 601us/step - loss: 0.4219 - acc: 0.8010 - val_loss: 0.6101 - val_acc: 0.6616\n",
      "Epoch 125/150\n",
      "1050/1050 [==============================] - 1s 602us/step - loss: 0.4245 - acc: 0.8000 - val_loss: 0.6114 - val_acc: 0.6730\n",
      "Epoch 126/150\n",
      "1050/1050 [==============================] - 1s 598us/step - loss: 0.4165 - acc: 0.8076 - val_loss: 0.6093 - val_acc: 0.6806\n",
      "Epoch 127/150\n",
      "1050/1050 [==============================] - 1s 603us/step - loss: 0.4240 - acc: 0.8124 - val_loss: 0.6149 - val_acc: 0.6806\n",
      "Epoch 128/150\n",
      "1050/1050 [==============================] - 1s 609us/step - loss: 0.4177 - acc: 0.8010 - val_loss: 0.6101 - val_acc: 0.6692\n",
      "Epoch 129/150\n",
      "1050/1050 [==============================] - 1s 596us/step - loss: 0.4242 - acc: 0.7952 - val_loss: 0.6091 - val_acc: 0.6692\n",
      "Epoch 130/150\n",
      "1050/1050 [==============================] - 1s 605us/step - loss: 0.4234 - acc: 0.8019 - val_loss: 0.6098 - val_acc: 0.6806\n",
      "Epoch 131/150\n",
      "1050/1050 [==============================] - 1s 601us/step - loss: 0.4168 - acc: 0.8019 - val_loss: 0.6211 - val_acc: 0.6844\n",
      "Epoch 132/150\n",
      "1050/1050 [==============================] - 1s 711us/step - loss: 0.4202 - acc: 0.7981 - val_loss: 0.6131 - val_acc: 0.6768\n",
      "Epoch 133/150\n",
      "1050/1050 [==============================] - 1s 687us/step - loss: 0.4161 - acc: 0.8124 - val_loss: 0.6101 - val_acc: 0.6730\n",
      "Epoch 134/150\n",
      "1050/1050 [==============================] - 1s 688us/step - loss: 0.4142 - acc: 0.8171 - val_loss: 0.6187 - val_acc: 0.6882\n",
      "Epoch 135/150\n",
      "1050/1050 [==============================] - 1s 674us/step - loss: 0.4121 - acc: 0.8010 - val_loss: 0.6221 - val_acc: 0.6806\n",
      "Epoch 136/150\n",
      "1050/1050 [==============================] - 1s 697us/step - loss: 0.4134 - acc: 0.8048 - val_loss: 0.6114 - val_acc: 0.6730\n",
      "Epoch 137/150\n",
      "1050/1050 [==============================] - 1s 654us/step - loss: 0.4103 - acc: 0.8143 - val_loss: 0.6134 - val_acc: 0.6692\n",
      "Epoch 138/150\n",
      "1050/1050 [==============================] - 1s 768us/step - loss: 0.4146 - acc: 0.8105 - val_loss: 0.6114 - val_acc: 0.6730\n",
      "Epoch 139/150\n",
      "1050/1050 [==============================] - 1s 714us/step - loss: 0.4084 - acc: 0.8038 - val_loss: 0.6124 - val_acc: 0.6730\n",
      "Epoch 140/150\n",
      "1050/1050 [==============================] - 1s 673us/step - loss: 0.4042 - acc: 0.8152 - val_loss: 0.6117 - val_acc: 0.6692\n",
      "Epoch 141/150\n",
      "1050/1050 [==============================] - 1s 662us/step - loss: 0.4137 - acc: 0.8048 - val_loss: 0.6117 - val_acc: 0.6806\n",
      "Epoch 142/150\n",
      "1050/1050 [==============================] - 1s 610us/step - loss: 0.4033 - acc: 0.8200 - val_loss: 0.6126 - val_acc: 0.6768\n",
      "Epoch 143/150\n",
      "1050/1050 [==============================] - 1s 665us/step - loss: 0.4092 - acc: 0.8133 - val_loss: 0.6135 - val_acc: 0.6692\n",
      "Epoch 144/150\n",
      "1050/1050 [==============================] - 1s 696us/step - loss: 0.4045 - acc: 0.8124 - val_loss: 0.6139 - val_acc: 0.6692\n",
      "Epoch 145/150\n",
      "1050/1050 [==============================] - 1s 785us/step - loss: 0.4061 - acc: 0.8076 - val_loss: 0.6177 - val_acc: 0.6654\n",
      "Epoch 146/150\n",
      "1050/1050 [==============================] - 1s 738us/step - loss: 0.4037 - acc: 0.8248 - val_loss: 0.6135 - val_acc: 0.6768\n",
      "Epoch 147/150\n",
      "1050/1050 [==============================] - 1s 745us/step - loss: 0.4005 - acc: 0.8124 - val_loss: 0.6219 - val_acc: 0.6654\n",
      "Epoch 148/150\n",
      "1050/1050 [==============================] - 1s 682us/step - loss: 0.4045 - acc: 0.8057 - val_loss: 0.6171 - val_acc: 0.6654\n",
      "Epoch 149/150\n",
      "1050/1050 [==============================] - 1s 639us/step - loss: 0.4029 - acc: 0.8200 - val_loss: 0.6173 - val_acc: 0.6654\n",
      "Epoch 150/150\n",
      "1050/1050 [==============================] - 1s 679us/step - loss: 0.3970 - acc: 0.8352 - val_loss: 0.6150 - val_acc: 0.6730\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(os.path.join(experiment_path, 'weights.{epoch:03d}-{val_loss:.2f} hdf5'),\n",
    "                   monitor='val_loss',\n",
    "                   save_best_only=False,\n",
    "                   save_weights_only=False,),\n",
    "    TensorBoard(log_dir=os.path.join(experiment_path, 'logs'))\n",
    "]\n",
    "\n",
    "print('\\nTraining...')\n",
    "h = mobile.fit(train_X, train_Y, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 0s 275us/step\n",
      "Test loss: 0.5890716702017741\n",
      "Test accuracy: 0.6747720365647487\n"
     ]
    }
   ],
   "source": [
    "mobile_eval = mobile.evaluate(test_X, test_Y_one_hot, verbose=1)\n",
    "\n",
    "print('Test loss:', mobile_eval[0])\n",
    "print('Test accuracy:', mobile_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# calculate predictions\n",
    "predictions = mobile.predict(test_X)\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enfermito = load_image('fondo_de_ojo_train/enfermo/train_enfermo1.jpg', weights)\n",
    "sanito = load_image('fondo_de_ojo_train/sano/train_sano10.jpg', weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 1280)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1 = enfermito/255\n",
    "n2 = sanito/255\n",
    "n = np.array([n1, n2])\n",
    "n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "predictions = mobile.predict(n)\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
