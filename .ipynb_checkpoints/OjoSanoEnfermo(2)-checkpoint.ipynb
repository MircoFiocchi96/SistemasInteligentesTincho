{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import keras as ks\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import imagenet_utils\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn.utils import shuffle\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPool2D, GlobalAveragePooling2D, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "weights = ks.applications.mobilenet_v2.MobileNetV2(input_shape=(224,224,3), include_top=False, weights='imagenet', pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(f, l, m):\n",
    "    e_l = []\n",
    "    feat_l = []\n",
    "    for filename in tqdm(os.listdir(f)):\n",
    "        img_path = os.path.join(f, filename)\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        e = m.predict(x)\n",
    "\n",
    "        e_l.append(e)\n",
    "        feat_l.append(l)\n",
    "        \n",
    "    return e_l, feat_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(f, m):\n",
    "    img_path = os.path.join('', f)\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    e = m.predict(x)\n",
    "        \n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 817/827 [00:59<00:00, 11.88it/s]"
     ]
    }
   ],
   "source": [
    "enfermos, feat_enfermos = load_images_from_folder('fondo_de_ojo_train/enfermo/', 0, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanos, feat_sanos = load_images_from_folder('fondo_de_ojo_train/sano/', 1, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sanos + enfermos\n",
    "Y = feat_sanos + feat_enfermos\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "X,Y = shuffle(X, Y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (1313, 1, 1280) (1313,)\n",
      "Testing data shape :  (329, 1, 1280) (329,)\n"
     ]
    }
   ],
   "source": [
    "train_X,test_X,train_Y,test_Y = train_test_split(X,Y,test_size=0.2)\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.unique(train_Y)\n",
    "nClasses = len(classes)\n",
    "nClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: 1\n",
      "After conversion to one-hot: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    " \n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label:', train_Y[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, valid_X, train_Y, valid_Y = train_test_split(train_X, train_Y_one_hot, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1, 1280)           1639680   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1280)              1639680   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 3,281,922\n",
      "Trainable params: 3,281,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INIT_LR = 1e-3\n",
    "epochs = 150\n",
    "batch_size = 64\n",
    "exp_name = 'e02'\n",
    "\n",
    "mobile = Sequential()\n",
    "mobile.add(Dense(input_shape=[1,train_X[0][0].shape[0]], units=train_X[0][0].shape[0]))\n",
    "mobile.add(Flatten())\n",
    "mobile.add(Dropout(0.5))\n",
    "mobile.add(Dense(input_shape=[1,train_X[0][0].shape[0]], units=train_X[0][0].shape[0], activation='linear'))\n",
    "mobile.add(Dropout(0.5)) \n",
    "mobile.add(Dense(2, input_shape=(train_X[:][:].shape[0],), activation='softmax'))\n",
    "\n",
    "mobile.summary()\n",
    "\n",
    "mobile.compile(loss=ks.losses.categorical_crossentropy, optimizer=ks.optimizers.Adagrad(lr=INIT_LR, decay=INIT_LR / 100),metrics=['accuracy'])\n",
    "\n",
    "experiment_path = os.path.join(' ./experimento/' + exp_name)\n",
    "if not os.path.exists(experiment_path):\n",
    "    os.makedirs(experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1050 samples, validate on 263 samples\n",
      "Epoch 1/100\n",
      "1050/1050 [==============================] - 1s 1ms/step - loss: 0.6888 - acc: 0.5448 - val_loss: 0.6923 - val_acc: 0.4791\n",
      "Epoch 2/100\n",
      "1050/1050 [==============================] - 1s 642us/step - loss: 0.6702 - acc: 0.6257 - val_loss: 0.6702 - val_acc: 0.6388\n",
      "Epoch 3/100\n",
      "1050/1050 [==============================] - 1s 575us/step - loss: 0.6590 - acc: 0.6238 - val_loss: 0.6580 - val_acc: 0.5970\n",
      "Epoch 4/100\n",
      "1050/1050 [==============================] - 1s 574us/step - loss: 0.6407 - acc: 0.6505 - val_loss: 0.6741 - val_acc: 0.6046\n",
      "Epoch 5/100\n",
      "1050/1050 [==============================] - 1s 567us/step - loss: 0.6325 - acc: 0.6600 - val_loss: 0.6464 - val_acc: 0.5894\n",
      "Epoch 6/100\n",
      "1050/1050 [==============================] - 1s 571us/step - loss: 0.6219 - acc: 0.6581 - val_loss: 0.6418 - val_acc: 0.6350\n",
      "Epoch 7/100\n",
      "1050/1050 [==============================] - 1s 576us/step - loss: 0.6096 - acc: 0.6733 - val_loss: 0.6388 - val_acc: 0.6274\n",
      "Epoch 8/100\n",
      "1050/1050 [==============================] - 1s 576us/step - loss: 0.6021 - acc: 0.6838 - val_loss: 0.6578 - val_acc: 0.6502\n",
      "Epoch 9/100\n",
      "1050/1050 [==============================] - 1s 575us/step - loss: 0.6002 - acc: 0.6724 - val_loss: 0.6371 - val_acc: 0.5741\n",
      "Epoch 10/100\n",
      "1050/1050 [==============================] - 1s 633us/step - loss: 0.5911 - acc: 0.6848 - val_loss: 0.6470 - val_acc: 0.6502\n",
      "Epoch 11/100\n",
      "1050/1050 [==============================] - 1s 745us/step - loss: 0.5872 - acc: 0.6990 - val_loss: 0.6348 - val_acc: 0.5856\n",
      "Epoch 12/100\n",
      "1050/1050 [==============================] - 1s 686us/step - loss: 0.5768 - acc: 0.6914 - val_loss: 0.6507 - val_acc: 0.6502\n",
      "Epoch 13/100\n",
      "1050/1050 [==============================] - 1s 750us/step - loss: 0.5794 - acc: 0.6971 - val_loss: 0.6333 - val_acc: 0.6236\n",
      "Epoch 14/100\n",
      "1050/1050 [==============================] - 1s 672us/step - loss: 0.5760 - acc: 0.7076 - val_loss: 0.6326 - val_acc: 0.6122\n",
      "Epoch 15/100\n",
      "1050/1050 [==============================] - 1s 591us/step - loss: 0.5692 - acc: 0.6981 - val_loss: 0.6455 - val_acc: 0.6388\n",
      "Epoch 16/100\n",
      "1050/1050 [==============================] - 1s 587us/step - loss: 0.5689 - acc: 0.6943 - val_loss: 0.6359 - val_acc: 0.6312\n",
      "Epoch 17/100\n",
      "1050/1050 [==============================] - 1s 607us/step - loss: 0.5640 - acc: 0.7048 - val_loss: 0.6646 - val_acc: 0.6616\n",
      "Epoch 18/100\n",
      "1050/1050 [==============================] - 1s 622us/step - loss: 0.5606 - acc: 0.7019 - val_loss: 0.6448 - val_acc: 0.6464\n",
      "Epoch 19/100\n",
      "1050/1050 [==============================] - 1s 625us/step - loss: 0.5620 - acc: 0.7105 - val_loss: 0.6337 - val_acc: 0.6046\n",
      "Epoch 20/100\n",
      "1050/1050 [==============================] - 1s 591us/step - loss: 0.5568 - acc: 0.7010 - val_loss: 0.6440 - val_acc: 0.6502\n",
      "Epoch 21/100\n",
      "1050/1050 [==============================] - 1s 598us/step - loss: 0.5509 - acc: 0.7181 - val_loss: 0.6380 - val_acc: 0.6350\n",
      "Epoch 22/100\n",
      "1050/1050 [==============================] - 1s 600us/step - loss: 0.5514 - acc: 0.7029 - val_loss: 0.7042 - val_acc: 0.6502\n",
      "Epoch 23/100\n",
      "1050/1050 [==============================] - 1s 599us/step - loss: 0.5505 - acc: 0.7162 - val_loss: 0.6327 - val_acc: 0.6122\n",
      "Epoch 24/100\n",
      "1050/1050 [==============================] - 1s 604us/step - loss: 0.5416 - acc: 0.7267 - val_loss: 0.6731 - val_acc: 0.6616\n",
      "Epoch 25/100\n",
      "1050/1050 [==============================] - 1s 597us/step - loss: 0.5452 - acc: 0.7200 - val_loss: 0.6492 - val_acc: 0.6540\n",
      "Epoch 26/100\n",
      "1050/1050 [==============================] - 1s 599us/step - loss: 0.5397 - acc: 0.7086 - val_loss: 0.6325 - val_acc: 0.6198\n",
      "Epoch 27/100\n",
      "1050/1050 [==============================] - 1s 674us/step - loss: 0.5374 - acc: 0.7210 - val_loss: 0.6322 - val_acc: 0.6160\n",
      "Epoch 28/100\n",
      "1050/1050 [==============================] - 1s 681us/step - loss: 0.5321 - acc: 0.7267 - val_loss: 0.6371 - val_acc: 0.6312\n",
      "Epoch 29/100\n",
      "1050/1050 [==============================] - 1s 712us/step - loss: 0.5348 - acc: 0.7381 - val_loss: 0.6362 - val_acc: 0.6312\n",
      "Epoch 30/100\n",
      "1050/1050 [==============================] - 1s 639us/step - loss: 0.5275 - acc: 0.7267 - val_loss: 0.6332 - val_acc: 0.6122\n",
      "Epoch 31/100\n",
      "1050/1050 [==============================] - 1s 708us/step - loss: 0.5279 - acc: 0.7314 - val_loss: 0.6350 - val_acc: 0.6236\n",
      "Epoch 32/100\n",
      "1050/1050 [==============================] - 1s 649us/step - loss: 0.5263 - acc: 0.7276 - val_loss: 0.6343 - val_acc: 0.6198\n",
      "Epoch 33/100\n",
      "1050/1050 [==============================] - 1s 610us/step - loss: 0.5220 - acc: 0.7248 - val_loss: 0.6365 - val_acc: 0.6426\n",
      "Epoch 34/100\n",
      "1050/1050 [==============================] - 1s 601us/step - loss: 0.5231 - acc: 0.7352 - val_loss: 0.6371 - val_acc: 0.6464\n",
      "Epoch 35/100\n",
      "1050/1050 [==============================] - 1s 641us/step - loss: 0.5212 - acc: 0.7286 - val_loss: 0.6361 - val_acc: 0.6502\n",
      "Epoch 36/100\n",
      "1050/1050 [==============================] - 1s 688us/step - loss: 0.5147 - acc: 0.7495 - val_loss: 0.6363 - val_acc: 0.6008\n",
      "Epoch 37/100\n",
      "1050/1050 [==============================] - 1s 621us/step - loss: 0.5201 - acc: 0.7152 - val_loss: 0.6503 - val_acc: 0.6654\n",
      "Epoch 38/100\n",
      "1050/1050 [==============================] - 1s 610us/step - loss: 0.5149 - acc: 0.7438 - val_loss: 0.6299 - val_acc: 0.6122\n",
      "Epoch 39/100\n",
      "1050/1050 [==============================] - 1s 603us/step - loss: 0.5151 - acc: 0.7333 - val_loss: 0.6492 - val_acc: 0.6616\n",
      "Epoch 40/100\n",
      "1050/1050 [==============================] - 1s 627us/step - loss: 0.5142 - acc: 0.7390 - val_loss: 0.6447 - val_acc: 0.6578\n",
      "Epoch 41/100\n",
      "1050/1050 [==============================] - 1s 590us/step - loss: 0.5154 - acc: 0.7419 - val_loss: 0.6315 - val_acc: 0.6426\n",
      "Epoch 42/100\n",
      "1050/1050 [==============================] - 1s 602us/step - loss: 0.5119 - acc: 0.7419 - val_loss: 0.6500 - val_acc: 0.6730\n",
      "Epoch 43/100\n",
      "1050/1050 [==============================] - 1s 606us/step - loss: 0.5047 - acc: 0.7419 - val_loss: 0.6538 - val_acc: 0.6730\n",
      "Epoch 44/100\n",
      "1050/1050 [==============================] - 1s 599us/step - loss: 0.5058 - acc: 0.7333 - val_loss: 0.6693 - val_acc: 0.6730\n",
      "Epoch 45/100\n",
      "1050/1050 [==============================] - 1s 592us/step - loss: 0.5029 - acc: 0.7438 - val_loss: 0.6294 - val_acc: 0.6198\n",
      "Epoch 46/100\n",
      "1050/1050 [==============================] - 1s 605us/step - loss: 0.5091 - acc: 0.7410 - val_loss: 0.6307 - val_acc: 0.6464\n",
      "Epoch 47/100\n",
      "1050/1050 [==============================] - 1s 601us/step - loss: 0.4976 - acc: 0.7505 - val_loss: 0.6301 - val_acc: 0.6426\n",
      "Epoch 48/100\n",
      "1050/1050 [==============================] - 1s 606us/step - loss: 0.5016 - acc: 0.7533 - val_loss: 0.6273 - val_acc: 0.6122\n",
      "Epoch 49/100\n",
      "1050/1050 [==============================] - 1s 599us/step - loss: 0.5025 - acc: 0.7505 - val_loss: 0.6277 - val_acc: 0.6388\n",
      "Epoch 50/100\n",
      "1050/1050 [==============================] - 1s 607us/step - loss: 0.5011 - acc: 0.7467 - val_loss: 0.6292 - val_acc: 0.6426\n",
      "Epoch 51/100\n",
      "1050/1050 [==============================] - 1s 611us/step - loss: 0.4943 - acc: 0.7476 - val_loss: 0.6314 - val_acc: 0.6426\n",
      "Epoch 52/100\n",
      "1050/1050 [==============================] - 1s 606us/step - loss: 0.4919 - acc: 0.7457 - val_loss: 0.6559 - val_acc: 0.6844\n",
      "Epoch 53/100\n",
      "1050/1050 [==============================] - 1s 613us/step - loss: 0.4957 - acc: 0.7543 - val_loss: 0.6268 - val_acc: 0.6312\n",
      "Epoch 54/100\n",
      "1050/1050 [==============================] - 1s 620us/step - loss: 0.4939 - acc: 0.7590 - val_loss: 0.6268 - val_acc: 0.6312\n",
      "Epoch 55/100\n",
      "1050/1050 [==============================] - 1s 631us/step - loss: 0.4928 - acc: 0.7638 - val_loss: 0.6319 - val_acc: 0.6464\n",
      "Epoch 56/100\n",
      "1050/1050 [==============================] - 1s 619us/step - loss: 0.4897 - acc: 0.7610 - val_loss: 0.6326 - val_acc: 0.6464\n",
      "Epoch 57/100\n",
      "1050/1050 [==============================] - 1s 623us/step - loss: 0.4848 - acc: 0.7619 - val_loss: 0.6389 - val_acc: 0.6730\n",
      "Epoch 58/100\n",
      "1050/1050 [==============================] - 1s 594us/step - loss: 0.4843 - acc: 0.7552 - val_loss: 0.6402 - val_acc: 0.6692\n",
      "Epoch 59/100\n",
      "1050/1050 [==============================] - 1s 585us/step - loss: 0.4875 - acc: 0.7581 - val_loss: 0.6409 - val_acc: 0.6730\n",
      "Epoch 60/100\n",
      "1050/1050 [==============================] - 1s 586us/step - loss: 0.4859 - acc: 0.7581 - val_loss: 0.6556 - val_acc: 0.6844\n",
      "Epoch 61/100\n",
      "1050/1050 [==============================] - 1s 590us/step - loss: 0.4771 - acc: 0.7638 - val_loss: 0.6264 - val_acc: 0.6426\n",
      "Epoch 62/100\n",
      "1050/1050 [==============================] - 1s 598us/step - loss: 0.4831 - acc: 0.7686 - val_loss: 0.6389 - val_acc: 0.6616\n",
      "Epoch 63/100\n",
      "1050/1050 [==============================] - 1s 671us/step - loss: 0.4854 - acc: 0.7562 - val_loss: 0.6275 - val_acc: 0.6502\n",
      "Epoch 64/100\n",
      "1050/1050 [==============================] - 1s 626us/step - loss: 0.4797 - acc: 0.7705 - val_loss: 0.6404 - val_acc: 0.6616\n",
      "Epoch 65/100\n",
      "1050/1050 [==============================] - 1s 632us/step - loss: 0.4804 - acc: 0.7648 - val_loss: 0.6453 - val_acc: 0.6806\n",
      "Epoch 66/100\n",
      "1050/1050 [==============================] - 1s 604us/step - loss: 0.4763 - acc: 0.7762 - val_loss: 0.6292 - val_acc: 0.6578\n",
      "Epoch 67/100\n",
      "1050/1050 [==============================] - 1s 608us/step - loss: 0.4785 - acc: 0.7667 - val_loss: 0.6244 - val_acc: 0.6540\n",
      "Epoch 68/100\n",
      "1050/1050 [==============================] - 1s 609us/step - loss: 0.4760 - acc: 0.7676 - val_loss: 0.6241 - val_acc: 0.6540\n",
      "Epoch 69/100\n",
      "1050/1050 [==============================] - 1s 619us/step - loss: 0.4699 - acc: 0.7762 - val_loss: 0.6289 - val_acc: 0.6616\n",
      "Epoch 70/100\n",
      "1050/1050 [==============================] - 1s 612us/step - loss: 0.4716 - acc: 0.7781 - val_loss: 0.6294 - val_acc: 0.6616\n",
      "Epoch 71/100\n",
      "1050/1050 [==============================] - 1s 616us/step - loss: 0.4725 - acc: 0.7714 - val_loss: 0.6264 - val_acc: 0.6578\n",
      "Epoch 72/100\n",
      "1050/1050 [==============================] - 1s 618us/step - loss: 0.4685 - acc: 0.7733 - val_loss: 0.6242 - val_acc: 0.6464\n",
      "Epoch 73/100\n",
      "1050/1050 [==============================] - 1s 654us/step - loss: 0.4687 - acc: 0.7771 - val_loss: 0.6262 - val_acc: 0.6616\n",
      "Epoch 74/100\n",
      "1050/1050 [==============================] - 1s 623us/step - loss: 0.4680 - acc: 0.7771 - val_loss: 0.6355 - val_acc: 0.6654\n",
      "Epoch 75/100\n",
      "1050/1050 [==============================] - 1s 609us/step - loss: 0.4617 - acc: 0.7771 - val_loss: 0.6272 - val_acc: 0.6654\n",
      "Epoch 76/100\n",
      "1050/1050 [==============================] - 1s 611us/step - loss: 0.4643 - acc: 0.7714 - val_loss: 0.6260 - val_acc: 0.6654\n",
      "Epoch 77/100\n",
      "1050/1050 [==============================] - 1s 618us/step - loss: 0.4583 - acc: 0.7771 - val_loss: 0.6267 - val_acc: 0.6692\n",
      "Epoch 78/100\n",
      "1050/1050 [==============================] - 1s 620us/step - loss: 0.4547 - acc: 0.7848 - val_loss: 0.6316 - val_acc: 0.6616\n",
      "Epoch 79/100\n",
      "1050/1050 [==============================] - 1s 687us/step - loss: 0.4614 - acc: 0.7771 - val_loss: 0.6332 - val_acc: 0.6730\n",
      "Epoch 80/100\n",
      "1050/1050 [==============================] - 1s 660us/step - loss: 0.4567 - acc: 0.7838 - val_loss: 0.6249 - val_acc: 0.6654\n",
      "Epoch 81/100\n",
      "1050/1050 [==============================] - 1s 620us/step - loss: 0.4594 - acc: 0.7648 - val_loss: 0.6242 - val_acc: 0.6540\n",
      "Epoch 82/100\n",
      "1050/1050 [==============================] - 1s 628us/step - loss: 0.4550 - acc: 0.7829 - val_loss: 0.6315 - val_acc: 0.6654\n",
      "Epoch 83/100\n",
      "1050/1050 [==============================] - 1s 670us/step - loss: 0.4526 - acc: 0.7819 - val_loss: 0.6301 - val_acc: 0.6616\n",
      "Epoch 84/100\n",
      "1050/1050 [==============================] - 1s 621us/step - loss: 0.4568 - acc: 0.7867 - val_loss: 0.6255 - val_acc: 0.6236\n",
      "Epoch 85/100\n",
      "1050/1050 [==============================] - 1s 632us/step - loss: 0.4510 - acc: 0.7914 - val_loss: 0.6296 - val_acc: 0.6692\n",
      "Epoch 86/100\n",
      "1050/1050 [==============================] - 1s 628us/step - loss: 0.4470 - acc: 0.7829 - val_loss: 0.6315 - val_acc: 0.6692\n",
      "Epoch 87/100\n",
      "1050/1050 [==============================] - 1s 626us/step - loss: 0.4539 - acc: 0.7876 - val_loss: 0.6241 - val_acc: 0.6692\n",
      "Epoch 88/100\n",
      "1050/1050 [==============================] - 1s 608us/step - loss: 0.4508 - acc: 0.7933 - val_loss: 0.6356 - val_acc: 0.6616\n",
      "Epoch 89/100\n",
      "1050/1050 [==============================] - 1s 617us/step - loss: 0.4483 - acc: 0.7905 - val_loss: 0.6398 - val_acc: 0.6730\n",
      "Epoch 90/100\n",
      "1050/1050 [==============================] - 1s 612us/step - loss: 0.4452 - acc: 0.7971 - val_loss: 0.6499 - val_acc: 0.6540\n",
      "Epoch 91/100\n",
      "1050/1050 [==============================] - 1s 625us/step - loss: 0.4490 - acc: 0.7867 - val_loss: 0.6249 - val_acc: 0.6692\n",
      "Epoch 92/100\n",
      "1050/1050 [==============================] - 1s 626us/step - loss: 0.4462 - acc: 0.7867 - val_loss: 0.6269 - val_acc: 0.6198\n",
      "Epoch 93/100\n",
      "1050/1050 [==============================] - 1s 626us/step - loss: 0.4471 - acc: 0.7990 - val_loss: 0.6361 - val_acc: 0.6616\n",
      "Epoch 94/100\n",
      "1050/1050 [==============================] - 1s 714us/step - loss: 0.4449 - acc: 0.7848 - val_loss: 0.6258 - val_acc: 0.6692\n",
      "Epoch 95/100\n",
      "1050/1050 [==============================] - 1s 668us/step - loss: 0.4410 - acc: 0.7838 - val_loss: 0.6331 - val_acc: 0.6730\n",
      "Epoch 96/100\n",
      "1050/1050 [==============================] - 1s 606us/step - loss: 0.4439 - acc: 0.7838 - val_loss: 0.6302 - val_acc: 0.6654\n",
      "Epoch 97/100\n",
      "1050/1050 [==============================] - 1s 617us/step - loss: 0.4391 - acc: 0.7914 - val_loss: 0.6254 - val_acc: 0.6692\n",
      "Epoch 98/100\n",
      "1050/1050 [==============================] - 1s 650us/step - loss: 0.4412 - acc: 0.7857 - val_loss: 0.6464 - val_acc: 0.6578\n",
      "Epoch 99/100\n",
      "1050/1050 [==============================] - 1s 718us/step - loss: 0.4382 - acc: 0.7924 - val_loss: 0.6375 - val_acc: 0.6692\n",
      "Epoch 100/100\n",
      "1050/1050 [==============================] - 1s 633us/step - loss: 0.4330 - acc: 0.7943 - val_loss: 0.6257 - val_acc: 0.6578\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(os.path.join(experiment_path, 'weights.{epoch:03d}-{val_loss:.2f} hdf5'),\n",
    "                   monitor='val_loss',\n",
    "                   save_best_only=False,\n",
    "                   save_weights_only=False,),\n",
    "    TensorBoard(log_dir=os.path.join(experiment_path, 'logs'))\n",
    "]\n",
    "\n",
    "print('\\nTraining...')\n",
    "h = mobile.fit(train_X, train_Y, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 0s 275us/step\n",
      "Test loss: 0.5890716702017741\n",
      "Test accuracy: 0.6747720365647487\n"
     ]
    }
   ],
   "source": [
    "mobile_eval = mobile.evaluate(test_X, test_Y_one_hot, verbose=1)\n",
    "\n",
    "print('Test loss:', mobile_eval[0])\n",
    "print('Test accuracy:', mobile_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# calculate predictions\n",
    "predictions = mobile.predict(test_X)\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enfermito = load_image('fondo_de_ojo_train/enfermo/train_enfermo1.jpg', weights)\n",
    "sanito = load_image('fondo_de_ojo_train/sano/train_sano10.jpg', weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 1280)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1 = enfermito/255\n",
    "n2 = sanito/255\n",
    "n = np.array([n1, n2])\n",
    "n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "predictions = mobile.predict(n)\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
